{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "# Setting up matplotlib to work interactively in a Jupyter environment\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)  # For Python's built-in random module\n",
    "tf.random.set_seed(seed_value)  # For TensorFlow\n",
    "\n",
    "# Don't show warning messages\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9e342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # Compute cross entropy loss\n",
    "    cross_entropy_loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Compute IoU loss\n",
    "    intersection = K.sum(K.abs(y_true * y_pred))\n",
    "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "    iou_loss = 1 - (intersection + 1) / (union + 1)  # Adding 1 to avoid division by zero\n",
    "    \n",
    "   \n",
    "    # Combine the losses\n",
    "    loss = cross_entropy_loss + .5* iou_loss   # Jaccard loss with binary cross entropy\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays\n",
    "IMG_HEIGHT = 1024\n",
    "per_image_norm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b78aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ptch_1024 = UNET(IMG_HEIGHT)\n",
    "base_ptch_1024.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train_model(base_ptch_1024, train_gen, val_gen):\n",
    "    # Define the ModelCheckpoint callback to save only the best model based on validation loss\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.h5',  # This is the file path where the best model will be saved\n",
    "        monitor='val_loss',  # Monitor validation loss to determine the best model\n",
    "        verbose=1,\n",
    "        save_best_only=True,  # Save only the model that has the best 'val_loss'\n",
    "        mode='min'  # The monitoring metric (here, 'val_loss') is expected to minimize\n",
    "    )\n",
    "\n",
    "    # Define other callbacks as needed, e.g., for early stopping or logging with TensorBoard\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        model_checkpoint_callback  # Include the ModelCheckpoint callback here\n",
    "    ]\n",
    "\n",
    "    # Fit the model with your training and validation data\n",
    "    results = base_ptch_1024.model.fit(\n",
    "        train_gen,\n",
    "        epochs=70,\n",
    "        steps_per_epoch=int(len(t_list)/btch_sz),  # Explicitly set this   # changed train_list \n",
    "        validation_data=val_gen,\n",
    "        validation_steps=int(len(v_list)/btch_sz),  # And this\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e92a5f",
   "metadata": {},
   "source": [
    "### Sample Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65367299",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_WIDTH = 1024\n",
    "IMG_CHANNELS = 1\n",
    "per_image_norm = False\n",
    "\n",
    "# Add these constants for brightness, saturation, and hue adjustments\n",
    "BRIGHTNESS = 0.2\n",
    "SATURATION = 0.3\n",
    "HUE = 0.25\n",
    "\n",
    "# Define Paths\n",
    "data_path = r'< full_train_data_path >' \n",
    "lab_path =  r'< full_test_data_path >'\n",
    "part_data_path = r'< part_train_data >'   \n",
    "part_lab_path = r'< part_test_data >'\n",
    "part_train_list = os.listdir(part_data_path)\n",
    "test_list = os.listdir(data_path)\n",
    "\n",
    "get_mean_and_std(data_path)\n",
    "train_gen, val_gen, test_gen_large = preprocess_and_load(data_path, part_data_path, part_lab_path, lab_path, train_list, test_list)\n",
    "\n",
    "train_model(base_ptch_1024, train_gen, val_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
