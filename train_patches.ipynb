{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec0751e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unet_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2348\\3610197121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnbimporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0munet_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUNET\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unet_model'"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "from unet_model import UNET\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from patchify import patchify, unpatchify\n",
    "import random\n",
    " \n",
    "%matplotlib inline\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "from keras.utils.np_utils import normalize\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.utils import normalize\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da376b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # Compute cross entropy loss\n",
    "    cross_entropy_loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Compute IoU loss\n",
    "    intersection = K.sum(K.abs(y_true * y_pred))\n",
    "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
    "    iou_loss = 1 - (intersection + 1) / (union + 1)  # Adding 1 to avoid division by zero\n",
    "    \n",
    "   \n",
    "    # Combine the losses\n",
    "    loss = cross_entropy_loss + 0.1*iou_loss   # Jaccard loss with binary cross entropy\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ptch_512 = UNET(IMG_HEIGHT)\n",
    "base_ptch_512.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these constants for brightness, saturation, and hue adjustments\n",
    "BRIGHTNESS = 0.2\n",
    "SATURATION = 0.3\n",
    "HUE = 0.25\n",
    "\n",
    "# Create empty arrays\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "IMG_CHANNELS = 1\n",
    "step_size = 386\n",
    "patch_sz = 512\n",
    "include_full_size_img = False\n",
    "\n",
    "per_image_norm = False\n",
    "\n",
    "val_set = 0.1\n",
    "t_list = train_list[0:int((1-val_set)*len(train_list))]\n",
    "v_list = train_list[int((1-val_set)*len(train_list)):]\n",
    "train_gen = image_data_generator(t_list,train_data_pth,train_mask_pth, batch_size=32, data_aug=True)\n",
    "val_gen = image_data_generator(v_list,train_data_pth,train_mask_pth, batch_size=32, data_aug=False)\n",
    "\n",
    "\n",
    "test_gen_large = image_data_generator(test_list_large,data_path_large,lab_path_large, batch_size=32, data_aug=False, main_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60685d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('20%', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]\n",
    "\n",
    "results = base_ptch_512.model.fit_generator(train_gen, epochs=50, steps_per_epoch=int(len(t_list)/32),\n",
    "                              validation_data=val_gen, validation_steps=int(len(v_list)/32),\n",
    "                              callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
